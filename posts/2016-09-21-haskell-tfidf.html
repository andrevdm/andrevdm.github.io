<?xml version="1.0" encoding="UTF-8" ?>
<!DOCTYPE html PUBLIC "-//W3C//DTD XHTML 1.0 Strict//EN" "http://www.w3.org/TR/xhtml1/DTD/xhtml1-strict.dtd">
<html xmlns="http://www.w3.org/1999/xhtml" xml:lang="en" lang="en">
    <head>
        <meta http-equiv="Content-Type" content="text/html; charset=UTF-8" />
        <title>Andre's Blog</title>
        <link rel="stylesheet" type="text/css" href="../css/default.css" />
        <link rel="stylesheet" type="text/css" href="../css/syntax.css" />
    </head>
    <body>
        <div id="header">
            <div id="logo">
                <a href="../">Blog</a>
            </div>
            <div id="navigation">
                <a href="../">Home</a>
                <a href="../contact.html">Contact</a>
                <!-- <a href="/about.html">About</a> -->
            </div>
        </div>

        <div id="content">
            <h1><a href="#top">Haskell text classification using Tf-Idf</a></h1>

            <div class="info">
    Posted on September 21, 2016
    
</div>

<p>This is part two in a two part blog series about haskell terminal applications, this blog shows a simple text classification implementation using techniques from <a href="2016-09-20-haskell-shell.html">part one</a>.</p>
<hr />
<h1 id="text-classification-with-tf-idf">Text Classification with Tf-Idf</h1>
<p>There are many ways to classify documents ranging from simple to very complex. The algorithm I’m using here is called Tf-Idf or “term frequency / inverse document frequency”. There are a number of sites that explain how it works better in detail than I would. See for example</p>
<ol style="list-style-type: decimal">
<li><a href="https://en.wikipedia.org/wiki/Tf%E2%80%93idf">Wikipedia</a></li>
<li><a href="http://www.tfidf.com/">What does tf-idf mean?</a></li>
</ol>
<p>Basically Tf-Idf counts the number of times a term occurs (term frequency) and combines that with a negative weighting for the number of times the term occurs in all categories. This means that common words that exist in multiple categories are going to count less towards the final score.</p>
<p>There are also multiple ways that TfIdf itself can be implemented e.g. with different algorithms for weighting the Tf vs the Idf or using n-grams (where n &gt; 1). I’m going with a pretty simple implementation but even with that I’ve seen pretty accurate results with the classifications I’m doing. I’m primarily using this for classifying short sentences of text. So it has been tested for simple matching on relatively small documents.</p>
<hr />
<h1 id="the-textclassification-application">The TextClassification application</h1>
<p>You can get the source for TextClassify at <a href="https://github.com/andrevdm/TextClassify" class="uri">https://github.com/andrevdm/TextClassify</a>. The code is reasonably well commented IMO, so I wont go into too much detail here on every line of code</p>
<p>Below I’ll discuss some implementation details not covered by the code comments.</p>
<hr />
<h1 id="using-the-application">Using the application</h1>
<ol style="list-style-type: decimal">
<li>The user sets up a directory of text files, one file per category.
<ul>
<li>These files contain the text that each category should match against.</li>
<li>Since, in this implementation, I’m not using n-grams each file is treated as a “bag of words” and newlines etc are ignored.</li>
</ul></li>
<li>Given the set of categories (the training set) the user then provides an input file (or piped via stdin) containing the text to be matched.
<ul>
<li>The data can be provided in plain text or in a CSV</li>
</ul></li>
<li>The application will ‘clean’ the input data and classify it</li>
<li>The results will be written to stdout and can be piped to a file if required</li>
</ol>
<hr />
<h1 id="using-sed-awk-and-column">Using sed, awk and column</h1>
<p>There are a large number of existing terminal applications so it often makes sense to use this existing functionality as well as writing terminal applications so that they too can be reused.</p>
<h2 id="removing-lines-with-awk">Removing lines with awk</h2>
<p>The CSV files I work with have a header that needs to be removed. Here is a awk script (removePrefix.awk) to do that</p>
<div class="sourceCode"><pre class="sourceCode awk"><code class="sourceCode awk"><span class="co">#!/usr/bin/awk -f</span>
<span class="kw">BEGIN</span> <span class="kw">{</span>FS = <span class="st">&quot;,&quot;</span>;<span class="kw">}</span>
NR&lt;<span class="dv">7</span> <span class="kw">{next}</span>
NF <span class="kw">{</span> <span class="kw">print</span> <span class="kw">}</span> 
<span class="kw">END</span> <span class="kw">{</span> <span class="kw">}</span></code></pre></div>
<p>This script can be used to pre-process the CSV file</p>
<div class="sourceCode"><pre class="sourceCode bash"><code class="sourceCode bash"><span class="kw">removePrevfix.awk</span> souceFile.csv</code></pre></div>
<h2 id="cleaning-text-with-sed">Cleaning text with sed</h2>
<p>The higher the quality of the input data to the classification algorithm the better the results will be. Some regular expressions can clean up the input text nicely. Here is a sed script that does this</p>
<div class="sourceCode"><pre class="sourceCode sed"><code class="sourceCode sed"><span class="co">#!/bin/sed -uf</span>
<span class="kw">s</span><span class="st">/c</span><span class="ch">\*</span><span class="st">/ /</span><span class="dt">gi</span>
<span class="kw">s</span><span class="st">/jan</span><span class="ch">\|</span><span class="st">feb</span><span class="ch">\|</span><span class="st">mar</span><span class="ch">\|</span><span class="st">apr</span><span class="ch">\|</span><span class="st">may</span><span class="ch">\|</span><span class="st">jun</span><span class="ch">\|</span><span class="st">jul</span><span class="ch">\|</span><span class="st">aug</span><span class="ch">\|</span><span class="st">sep</span><span class="ch">\|</span><span class="st">oct</span><span class="ch">\|</span><span class="st">nov</span><span class="ch">\|</span><span class="st">dec/ /</span><span class="dt">gi</span>
<span class="kw">s</span><span class="st">/ </span><span class="ch">\+$</span><span class="st">//</span><span class="dt">gi</span>
<span class="kw">s</span><span class="st">/</span><span class="ch">\[\(\)</span><span class="st">!\-</span><span class="ch">\/*\\\]</span><span class="st">/ /</span><span class="dt">g</span>
<span class="kw">s</span><span class="st">/</span><span class="ch">[\.*\/\(\)</span><span class="st">_,</span><span class="ch">\]</span><span class="st">/ /</span><span class="dt">g</span>
<span class="kw">s</span><span class="st">/-/ /</span><span class="dt">g</span>
<span class="kw">s</span><span class="st">/</span><span class="ch">\t</span><span class="st">/ /</span><span class="dt">g</span>
<span class="kw">s</span><span class="st">/  </span><span class="ch">\+</span><span class="st">/ /</span><span class="dt">g</span>
<span class="kw">s</span><span class="st">/ </span><span class="ch">\+$</span><span class="st">//</span><span class="dt">gi</span>
<span class="kw">s</span><span class="st">/</span><span class="ch">^</span><span class="st"> </span><span class="ch">\+</span><span class="st">//</span><span class="dt">gi</span></code></pre></div>
<p>This sed script removes some common words (the months), removes special characters and multiple spaces. You can customise this or create one per type of input as required. The -u parameter is important as it disables buffering which may interfere with line-by-line processing.</p>
<p>The TextClassification application will start sed and keep it running. A line of input data will be passed to it and the result read back a line at a time.</p>
<h2 id="displaying-csv-results-with-column">Displaying CSV results with column</h2>
<p><code>column</code> can be used to show CSV data as an aligned table in the terminal. I’ll use this later to show the results of the classification.</p>
<div class="sourceCode"><pre class="sourceCode bash"><code class="sourceCode bash"><span class="kw">cat</span> sourceFile.csv <span class="kw">|</span> <span class="kw">column</span> -s , -t</code></pre></div>
<hr />
<h1 id="command-line-arguments">Command line arguments</h1>
<p><em>See Args.hs</em></p>
<p>As <a href="2016-09-20-haskell-shell.html">part one</a> showed I’m using <a href="https://hackage.haskell.org/package/optparse-generic">OptParse-generic</a> to parse the command line arguments.</p>
<div class="sourceCode"><pre class="sourceCode haskell"><code class="sourceCode haskell"><span class="kw">data</span> <span class="dt">Arguments</span> <span class="fu">=</span> <span class="dt">Arguments</span> {<span class="ot">train ::</span> <span class="dt">Text</span> <span class="fu">&lt;?&gt;</span> <span class="st">&quot;Path to training data&quot;</span>
                           ,<span class="ot">input ::</span> <span class="dt">Maybe</span> <span class="dt">Text</span> <span class="fu">&lt;?&gt;</span> <span class="st">&quot;Input file to categorise. If missing stdin will be used&quot;</span>
                           ,<span class="ot">parser ::</span> <span class="dt">Maybe</span> <span class="dt">Text</span> <span class="fu">&lt;?&gt;</span> <span class="st">&quot;Parser type, defaults to lines. Options are lines/detail/csv&quot;</span>
                           ,<span class="ot">popts ::</span> <span class="dt">Maybe</span> <span class="dt">Text</span> <span class="fu">&lt;?&gt;</span> <span class="st">&quot;Parser options&quot;</span>
                           ,<span class="ot">clean ::</span> <span class="dt">Maybe</span> <span class="dt">Text</span> <span class="fu">&lt;?&gt;</span> <span class="st">&quot;Options name of text cleaner - see docs&quot;</span>
                           } <span class="kw">deriving</span> (<span class="dt">Generic</span>, <span class="dt">Show</span>)
<span class="kw">instance</span> <span class="dt">ParseRecord</span> <span class="dt">Arguments</span></code></pre></div>
<p>This is the resulting help text from these arguments</p>
<div class="sourceCode"><pre class="sourceCode email"><code class="sourceCode email">  Usage: txtcls --train STRING [--input STRING] [--parser TEXT] [--popts TEXT]
                [--clean TEXT]
  
  Available options:
    -h,--help                Show this help text
    --train TEXT             Path to training data
    --input TEXT             Input file to categorise. If missing stdin will be
                             used
    --parser TEXT            Parser type, defaults to lines. Options are
                             lines/detail/csv
    --popts TEXT             Parser options
    --clean TEXT             Options name of text cleaner - see docs</code></pre></div>
<p>These arguments are then interpreted and stored in the Options type</p>
<div class="sourceCode"><pre class="sourceCode haskell"><code class="sourceCode haskell"><span class="kw">data</span> <span class="dt">Options</span> <span class="fu">=</span> <span class="dt">Options</span> {<span class="ot">trainingPath ::</span> <span class="dt">Text</span>
                       ,<span class="ot">parserType ::</span> <span class="dt">Text</span>
                       ,<span class="ot">parserOptions ::</span> <span class="dt">Maybe</span> <span class="dt">Text</span>
                       ,<span class="ot">txtCleaner ::</span> <span class="dt">Text</span> <span class="ot">-&gt;</span> <span class="dt">IO</span> <span class="dt">Text</span>
                       ,<span class="ot">hin ::</span> <span class="dt">Handle</span>
                       ,<span class="ot">hout ::</span> <span class="dt">Handle</span>
                       } </code></pre></div>
<h2 id="input-handle">Input handle</h2>
<p>hin is set to the handle of the input stream, stdin if no <code>--input</code> parameter is present else the handle for the file</p>
<div class="sourceCode"><pre class="sourceCode haskell"><code class="sourceCode haskell">hin_ <span class="ot">&lt;-</span> <span class="kw">case</span> unHelpful <span class="fu">$</span> input args <span class="kw">of</span>
           <span class="dt">Just</span> t <span class="ot">-&gt;</span> 
             openFile (Txt.unpack t) <span class="dt">ReadMode</span>
           <span class="dt">Nothing</span> <span class="ot">-&gt;</span>
              pure stdin</code></pre></div>
<hr />
<h1 id="text-cleaning-with-the-cleaning-script">Text cleaning with the cleaning script</h1>
<p>Above I showed a sed that could be used to clean the input text. However because this application can use a CSV as the input it can’t simply apply the cleaning to the entire file or even an entire line. Only the text being classified should be cleaned. To do this an instance of sed is started and fed the text to clean one line at a time. (Actually any app could be used as long as it reads and writes one line at a time). The name of the app / script to use is defined by the <code>--clean</code> parameter</p>
<div class="sourceCode"><pre class="sourceCode haskell"><code class="sourceCode haskell"><span class="co">-- | Build a 'cleaner'</span>
<span class="ot">getCleaner ::</span> <span class="dt">Maybe</span> <span class="dt">Text</span> <span class="ot">-&gt;</span> <span class="dt">IO</span> (<span class="dt">Text</span> <span class="ot">-&gt;</span> <span class="dt">IO</span> <span class="dt">Text</span>)
getCleaner mcmd <span class="fu">=</span> 
  <span class="kw">case</span> mcmd <span class="kw">of</span>
    <span class="co">-- | The cleaner uses the extenal process to do the actual cleaning. One line is writtent to the processes' stdin and then a value is read from its stdout </span>
    <span class="dt">Just</span> cmd <span class="ot">-&gt;</span> <span class="kw">do</span>
      (<span class="dt">Just</span> inp, <span class="dt">Just</span> outp, _, phandle) <span class="ot">&lt;-</span> createProcess (proc (Txt.unpack cmd) []) { std_out <span class="fu">=</span> <span class="dt">CreatePipe</span>, std_in <span class="fu">=</span> <span class="dt">CreatePipe</span> }
      hSetBuffering outp <span class="dt">NoBuffering</span>
      hSetBuffering inp <span class="dt">LineBuffering</span>
      pure <span class="fu">$</span> cleanText inp outp
    <span class="co">-- | No external cleaner. Just make the text lower case</span>
    <span class="dt">Nothing</span> <span class="ot">-&gt;</span>
      pure <span class="fu">$</span> pure <span class="fu">.</span> Txt.toLower

<span class="co">-- | Used by getCleaner to build a curried cleaner function</span>
<span class="ot">cleanText ::</span> <span class="dt">Handle</span> <span class="ot">-&gt;</span> <span class="dt">Handle</span> <span class="ot">-&gt;</span> <span class="dt">Text</span> <span class="ot">-&gt;</span> <span class="dt">IO</span> <span class="dt">Text</span>
cleanText inp outp txt <span class="fu">=</span> <span class="kw">do</span>
  hPutStrLn inp <span class="fu">$</span> Txt.unpack (Txt.toLower txt)
  pure <span class="fu">.</span> Txt.pack <span class="fu">=&lt;&lt;</span> hGetLine outp</code></pre></div>
<p>The <strong>getCleaner</strong> function is passed (the optional) name of the cleaner script. If a script was specified then a processes is started and a curried <strong>cleanText</strong> function is returned as the cleaning function. If no script was specified then the returned cleaning function simply performs a toLower on the text.</p>
<p><strong>cleanText</strong> writes a line to the input handle for the process and then immediately reads the response line.</p>
<hr />
<h1 id="reading-the-input-data">Reading the input data</h1>
<p>TextClassifier has three parsers</p>
<ol style="list-style-type: decimal">
<li>CSV - one of the columns is the data column</li>
<li>Lines - each line is the data</li>
<li>Detail - same as line but additional information is printed for each input line</li>
</ol>
<p>whileM_ is used to read a line of input at a time. The line is then passed to the appropriate parsers, i.e. CSV, line or detail.</p>
<div class="sourceCode"><pre class="sourceCode haskell"><code class="sourceCode haskell"><span class="co">-- | Read input a line at a time and pass it to the parser</span>
whileM_ (not <span class="fu">&lt;$&gt;</span> <span class="dt">IO</span><span class="fu">.</span>hIsEOF (Args.hin opts)) <span class="fu">$</span> <span class="kw">do</span>
  <span class="co">-- | line of data</span>
  origChars <span class="ot">&lt;-</span> <span class="dt">IO</span><span class="fu">.</span>hGetLine <span class="fu">$</span> Args.hin opts
  <span class="kw">let</span> origLine <span class="fu">=</span> Txt.pack origChars
  
  <span class="co">-- | parse the line and get the results to display</span>
  parsed <span class="ot">&lt;-</span> <span class="kw">case</span> parser <span class="kw">of</span>
              <span class="fu">---</span></code></pre></div>
<hr />
<h1 id="parsing-the-csv-data">Parsing the CSV Data</h1>
<p><em>See ClassifyCsv.hs and Classify.hs</em></p>
<p>I’m using <a href="https://hackage.haskell.org/package/cassava">Cassava</a> to read the CSV file as well as creating the output csv. Since I’m not interpreting any of the data apart from the text to be classified I’m simply reading the CSV as a vector of Text.</p>
<div class="sourceCode"><pre class="sourceCode haskell"><code class="sourceCode haskell"><span class="kw">let</span> contents <span class="fu">=</span> BL8.pack <span class="fu">.</span> Txt.unpack <span class="fu">$</span> line <span class="kw">in</span>
<span class="kw">let</span> parsed <span class="fu">=</span> decode <span class="dt">NoHeader</span><span class="ot"> contents ::</span> <span class="dt">Either</span> [<span class="dt">Char</span>] (<span class="dt">V.Vector</span> [<span class="dt">Text</span>]) <span class="kw">in</span></code></pre></div>
<p>Given a vector of Text it is simple to get the column containing the text to classify. The <strong>parseCsvLine</strong> function returns a <strong>ParsedLine a</strong> type which contains the text to be classified.</p>
<div class="sourceCode"><pre class="sourceCode haskell"><code class="sourceCode haskell"><span class="kw">newtype</span> <span class="dt">RawText</span> <span class="fu">=</span> <span class="dt">RawText</span> <span class="dt">Text</span> <span class="kw">deriving</span> (<span class="dt">Show</span>)
<span class="kw">data</span> <span class="dt">ParsedLine</span> a <span class="fu">=</span> <span class="dt">ParsedLine</span> <span class="dt">RawText</span> a <span class="kw">deriving</span> (<span class="dt">Show</span>)</code></pre></div>
<p>Remember that each line of data must be cleaned. Rather than having <strong>parseCsvLine</strong> live in IO it returns a <strong>ParsedLine a</strong> type. The code in Main then calls the cleaner and passes the resulting <strong>CleanedLine a</strong> to <strong>categoriseCsvLine</strong>. This limits the amount of code that needs to be in IO. It also make the code easier to test (e.g. from the REPL) as the two functions can be tested independently.</p>
<hr />
<h1 id="tf-idf">Tf-Idf</h1>
<h2 id="training-set">Training set</h2>
<p><em>See ClassifyIO.hs</em></p>
<p>The training set is a directory with a file per category. Each file contains the words for that category. To load the files the <strong>loadTrainingSet</strong> function is used</p>
<div class="sourceCode"><pre class="sourceCode haskell"><code class="sourceCode haskell"><span class="kw">newtype</span> <span class="dt">Category</span> <span class="fu">=</span> <span class="dt">Category</span> <span class="dt">Text</span> <span class="kw">deriving</span> (<span class="dt">Show</span>, <span class="dt">Eq</span>, <span class="dt">Ord</span>)
<span class="kw">data</span> <span class="dt">TrainingSet</span> <span class="fu">=</span> <span class="dt">TrainingSet</span> [(<span class="dt">Category</span>, [<span class="dt">Text</span>])] <span class="kw">deriving</span> (<span class="dt">Show</span>)

<span class="ot">loadTrainingSet ::</span> <span class="dt">Args.Options</span> <span class="ot">-&gt;</span> FilePath <span class="ot">-&gt;</span> <span class="dt">IO</span> <span class="dt">TrainingSet</span></code></pre></div>
<p>All .txt files in the directory are loaded and result in a category of words.</p>
<h2 id="tf-idf-1">Tf-Idf</h2>
<p><em>See TfIdf.hs</em></p>
<p>To review the terminology</p>
<ul>
<li>Term - a single word</li>
<li>Category - category name</li>
<li>Document - a document of terms mapped to their TfIdf value</li>
</ul>
<p>the <strong>train</strong> function takes a <strong>TrainingSet</strong> and creates a <strong>TrainedData</strong></p>
<div class="sourceCode"><pre class="sourceCode haskell"><code class="sourceCode haskell"><span class="co">-- | A term is a single word</span>
<span class="kw">newtype</span> <span class="dt">Term</span> <span class="fu">=</span> <span class="dt">Term</span> <span class="dt">Text</span> <span class="kw">deriving</span> (<span class="dt">Show</span>, <span class="dt">Eq</span>, <span class="dt">Ord</span>)
<span class="co">-- | A category name</span>
<span class="kw">newtype</span> <span class="dt">Category</span> <span class="fu">=</span> <span class="dt">Category</span> <span class="dt">Text</span> <span class="kw">deriving</span> (<span class="dt">Show</span>, <span class="dt">Eq</span>, <span class="dt">Ord</span>)
<span class="co">-- | Term frequency value</span>
<span class="kw">newtype</span> <span class="dt">Tf</span> <span class="fu">=</span> <span class="dt">Tf</span> <span class="dt">Double</span> <span class="kw">deriving</span> (<span class="dt">Show</span>)
<span class="co">-- | Inverse document frequency value</span>
<span class="kw">newtype</span> <span class="dt">Idf</span> <span class="fu">=</span> <span class="dt">Idf</span> <span class="dt">Double</span> <span class="kw">deriving</span> (<span class="dt">Show</span>)
<span class="co">-- | The combined Tf and Idf value</span>
<span class="kw">newtype</span> <span class="dt">TfIdf</span> <span class="fu">=</span> <span class="dt">TfIdf</span> <span class="dt">Double</span> <span class="kw">deriving</span> (<span class="dt">Show</span>)
<span class="co">-- | A document is a map of terms to TfIdf</span>
<span class="kw">newtype</span> <span class="dt">Document</span> <span class="fu">=</span> <span class="dt">Document</span> (<span class="dt">Map</span> <span class="dt">Term</span> <span class="dt">TfIdf</span>) <span class="kw">deriving</span> (<span class="dt">Show</span>)

<span class="co">-- | Data making up the training set</span>
<span class="kw">data</span> <span class="dt">TrainingSet</span> <span class="fu">=</span> <span class="dt">TrainingSet</span> [(<span class="dt">Category</span>, [<span class="dt">Text</span>])] <span class="kw">deriving</span> (<span class="dt">Show</span>)
<span class="co">-- | The trained data, each category linked to a document</span>
<span class="kw">data</span> <span class="dt">TrainedData</span> <span class="fu">=</span> <span class="dt">TrainedData</span> [(<span class="dt">Category</span>, <span class="dt">Document</span>)] <span class="kw">deriving</span> (<span class="dt">Show</span>)


<span class="ot">train ::</span> <span class="dt">TrainingSet</span> <span class="ot">-&gt;</span> <span class="dt">TrainedData</span></code></pre></div>
<p>Categorising text is handled by the <strong>categorise</strong> function. Given a collection of words it returns the best matching category if one was found. <strong>classifyDetail</strong> returns all possible matches sorted best match first. Both functions use cagegoriseWords to do the actual classification.</p>
<div class="sourceCode"><pre class="sourceCode haskell"><code class="sourceCode haskell"><span class="co">-- | Classify a line of text and try get the best matching category</span>
<span class="ot">classify ::</span> <span class="dt">Args.Options</span> <span class="ot">-&gt;</span> <span class="dt">TrainedData</span> <span class="ot">-&gt;</span> <span class="dt">Text</span> <span class="ot">-&gt;</span> <span class="dt">Maybe</span> (<span class="dt">Category</span>, <span class="dt">Double</span>) <span class="co">-- In Classify.hs</span>

<span class="co">-- | Classify a line of text and get all matching categories, best first</span>
<span class="ot">classifyDetail ::</span> <span class="dt">TrainedData</span> <span class="ot">-&gt;</span> <span class="dt">Text</span> <span class="ot">-&gt;</span> [(<span class="dt">Category</span>, <span class="dt">Double</span>)] <span class="co">-- In Classify.hs</span>


<span class="ot">categoriseWords ::</span> <span class="dt">TrainedData</span> <span class="ot">-&gt;</span> [<span class="dt">Text</span>] <span class="ot">-&gt;</span> [(<span class="dt">Category</span>, <span class="dt">Double</span>)]  <span class="co">-- in TfIdf.hs</span></code></pre></div>
<p>To calculate the Tf and the Idf values the following two functions are used</p>
<div class="sourceCode"><pre class="sourceCode haskell"><code class="sourceCode haskell"><span class="co">-- | Calgulate the term frequency for a collection of words</span>
<span class="co">-- | Tf = occurrence / terms in document.</span>
<span class="ot">calcTermFreq ::</span> [<span class="dt">Text</span>] <span class="ot">-&gt;</span> <span class="dt">Map</span> <span class="dt">Term</span> <span class="dt">Tf</span>
calcTermFreq terms <span class="fu">=</span>
  <span class="co">-- | Map of term to number of occurrences</span>
  <span class="kw">let</span> freq <span class="fu">=</span> Map.fromListWith (<span class="fu">+</span>) [(<span class="dt">Term</span> t, <span class="dv">1</span>) <span class="fu">|</span> t <span class="ot">&lt;-</span> terms] <span class="kw">in</span>
  <span class="co">-- | Document of Term to freq. Tf = occurrence count / terms in doc</span>
  (\d <span class="ot">-&gt;</span> <span class="dt">Tf</span> <span class="fu">$</span> d <span class="fu">/</span> fromIntegral(length terms)) <span class="fu">&lt;$&gt;</span> freq

<span class="co">-- | Claculate the term's inverse document frequency</span>
<span class="co">-- | Idf = (tf + 1) / (number of documents + 1)</span>
<span class="co">-- | + 1 is used to avoid divide by zero</span>
<span class="ot">calcTermIdf ::</span> [<span class="dt">Map</span> <span class="dt">Term</span> a] <span class="ot">-&gt;</span> <span class="dt">Term</span> <span class="ot">-&gt;</span> <span class="dt">Idf</span>
calcTermIdf termToTfs term <span class="fu">=</span>
  <span class="kw">let</span> docsWithTerm <span class="fu">=</span> filter identity (Map.member term <span class="fu">&lt;$&gt;</span> termToTfs) <span class="kw">in</span>
  <span class="dt">Idf</span> <span class="fu">$</span> log ((fromIntegral <span class="fu">.</span> length <span class="fu">$</span> termToTfs) <span class="fu">+</span> <span class="dv">1</span>) <span class="fu">/</span> ((fromIntegral <span class="fu">.</span> length <span class="fu">$</span> docsWithTerm) <span class="fu">+</span> <span class="dv">1</span>)</code></pre></div>
<p>Notice that there is no need for IO at all in the TfIdf module. It is given a loaded training set and cleaned text to classify.</p>
<p>The classification is then just finding the category with the closest matching tf-idf value</p>
<div class="sourceCode"><pre class="sourceCode haskell"><code class="sourceCode haskell"><span class="co">-- | Calculate how well terms matches categories</span>
<span class="ot">compareToCategory ::</span> [(<span class="dt">Term</span>,<span class="dt">TfIdf</span>)] <span class="ot">-&gt;</span> (<span class="dt">Category</span>, <span class="dt">Document</span>) <span class="ot">-&gt;</span> (<span class="dt">Category</span>, <span class="dt">Double</span>)
compareToCategory searchTfIdf (cat, <span class="dt">Document</span> catMap) <span class="fu">=</span>
  <span class="kw">let</span> catList <span class="fu">=</span> Map.toList catMap <span class="kw">in</span>

  <span class="co">-- | common words in the category and the search text</span>
  <span class="kw">let</span> common <span class="fu">=</span> Lst.intersectBy sameTerm catList searchTfIdf <span class="kw">in</span>
  <span class="kw">let</span> commonV <span class="fu">=</span> sum <span class="fu">$</span> valFromTfIdf <span class="fu">.</span> snd <span class="fu">&lt;$&gt;</span> common <span class="kw">in</span>

  <span class="co">-- | Sum of all the TfIdf values</span>
  <span class="kw">let</span> allV <span class="fu">=</span> sum (valFromTfIdf <span class="fu">.</span> snd <span class="fu">&lt;$&gt;</span> searchTfIdf) <span class="fu">+</span> sum (valFromTfIdf <span class="fu">.</span> snd <span class="fu">&lt;$&gt;</span> catList) <span class="kw">in</span>
  
  <span class="co">-- | Similarity = ((common a) + (common b)) / (sum all tfIdf)</span>
  (cat, (commonV <span class="fu">*</span> <span class="dv">2</span>) <span class="fu">/</span> allV)</code></pre></div>
<hr />
<h1 id="using-txtcls">Using txtcls</h1>
<h2 id="building">Building</h2>
<div class="sourceCode"><pre class="sourceCode bash"><code class="sourceCode bash"><span class="kw">git</span> clone git@github.com:andrevdm/TextClassify.git
<span class="kw">stack</span> build</code></pre></div>
<h2 id="installing">Installing</h2>
<div class="sourceCode"><pre class="sourceCode bash"><code class="sourceCode bash"><span class="kw">stack</span> install</code></pre></div>
<p>This will install txtcls into your local stack bin folder.</p>
<h2 id="usage-instructions">Usage Instructions</h2>
<div class="sourceCode"><pre class="sourceCode bash"><code class="sourceCode bash"><span class="kw">txtcls</span> --help</code></pre></div>
<div class="sourceCode"><pre class="sourceCode email"><code class="sourceCode email">txtcls - Text Classifier. Version 0.1.2

Usage: txtcls --train TEXT [--input TEXT] [--parser TEXT] [--popts TEXT]
              [--clean TEXT]

Available options:
  -h,--help                Show this help text
  --train TEXT             Path to training data
  --input TEXT             Input file to categorise. If missing stdin will be
                           used
  --parser TEXT            Parser type, defaults to lines. Options are
                           lines/detail/csv
  --popts TEXT             Parser options
  --clean TEXT             Options name of text cleaner - see docs</code></pre></div>
<h2 id="usage-examples">Usage examples</h2>
<p>The examples folder contains scripts showing how txtcls can be used. The files are</p>
<ol style="list-style-type: decimal">
<li>cleanText.sed - sed script for cleaning the words</li>
<li>skipLines.awk - awk script for skipping lines in the input CSV</li>
<li>egLines.txt - example of data where each line is the data</li>
<li>egCsv.csv - example of data in csv</li>
<li>egCsvWithHeader.csv - example of data in CSV with a header text</li>
<li>demoCsv.sh - run the example on egCsv.csv</li>
<li>demoLines.sh - run the example on egLines.txt<br />
</li>
<li>demoDetail.sh - run the example on egLines.txt using the detail output</li>
<li>demoCsvWithHeader.sh - run the example on egCsvWithHeader.csv</li>
<li>demoDetailInteractive.sh - run the detail parser interactively, read a line from stdin and write to stdout</li>
<li>trainingData/cs.txt</li>
<li>trainingData/hasekll.txt</li>
</ol>
<h2 id="lines">Lines</h2>
<div class="sourceCode"><pre class="sourceCode bash"><code class="sourceCode bash"><span class="kw">txtcls</span> --train ./trainingData --input egLines.txt --parser lines --clean ./cleanText.sed</code></pre></div>
<p>Where</p>
<ul>
<li><code class="sourceCode bash"><span class="kw">--train</span> ./trainingData</code>
<ul>
<li>is the path to the folder with the training data</li>
</ul></li>
<li><code class="sourceCode bash"><span class="kw">--input</span> egLines.txt</code>
<ul>
<li>is the data source to classify</li>
</ul></li>
<li><code class="sourceCode bash"><span class="kw">--parser</span> lines</code>
<ul>
<li>is the parser to use</li>
</ul></li>
<li><code class="sourceCode bash"><span class="kw">--clean</span> ./cleanText.sed</code>
<ul>
<li>is the external process or script to use to clean the text</li>
</ul></li>
</ul>
<h3 id="detail">Detail</h3>
<div class="sourceCode"><pre class="sourceCode bash"><code class="sourceCode bash"><span class="kw">txtcls</span> --train ./trainingData --input egLines.txt --parser detail --clean ./cleanText.sed</code></pre></div>
<p>Where</p>
<ul>
<li><code class="sourceCode bash"><span class="kw">--parser</span> detail</code>
<ul>
<li>is the parser to use</li>
</ul></li>
</ul>
<h3 id="csv">CSV</h3>
<div class="sourceCode"><pre class="sourceCode bash"><code class="sourceCode bash"><span class="kw">txtcls</span> --train ./trainingData --input egCsv.csv --parser csv --popts 2 --clean ./cleanText.sed <span class="kw">|</span> <span class="kw">column</span> -s , -t</code></pre></div>
<p>Where</p>
<ul>
<li><code class="sourceCode bash"><span class="kw">--popts</span> 2</code>
<ul>
<li>is column in the CSV data that contains the data to classify</li>
</ul></li>
<li><code class="sourceCode bash"><span class="kw">|</span> <span class="kw">column</span> -s , -t</code>
<ul>
<li>pipes the resulting CSV to column to display it as a table in the terminal window</li>
</ul></li>
</ul>
<h3 id="csv-with-header-text">CSV with header text</h3>
<pre class="./bash"><code>skipLines.awk egCsvWithHeader.csv | txtcls --train ./trainingData --parser csv --popts 2 --clean ./cleanText.sed | column -s , -t</code></pre>
<p>Where</p>
<ul>
<li><code class="sourceCode bash"><span class="kw">./skipLines.awk</span> egCsvWithHeader.csv <span class="kw">|</span></code>
<ul>
<li>uses the awk script to remove 4 lines from the input CSV. Note that there is no <code>--input</code> paramter so the input is read from stdin (here the output of awk)</li>
</ul></li>
</ul>
<h3 id="interactive">interactive</h3>
<div class="sourceCode"><pre class="sourceCode bash"><code class="sourceCode bash"><span class="kw">txtcls</span> --train ./trainingData --parser detail --clean ./cleanText.sed</code></pre></div>
<hr />
<h1 id="in-conclusion">In conclusion</h1>
<p>The source code for TextClassify is available and commented. You should hopefully be able to look at it and understand how it was implemented.</p>
<p>The important things to notice are</p>
<ul>
<li>How little needs to be in IO</li>
<li>How to use an external process (like sed) as part of your application’s pipeline</li>
<li>How to write your application so that it can be part of a larger pipeline (e.g. pipe the results of awk to it)</li>
<li>Selecting input from stdin or a file</li>
<li>Tf-Idf is a relatively simple but quite accurate way to classify simple documents</li>
</ul>
<hr />
<h1 id="links">Links</h1>
<ol style="list-style-type: decimal">
<li><a href="https://github.com/andrevdm/TextClassify">Source code for the examples</a></li>
<li><a href="https://hackage.haskell.org/package/optparse-generic">OptParse-generic</a></li>
<li><a href="https://hackage.haskell.org/package/cassava">Cassava</a></li>
<li><a href="https://www.haskellstack.org/">Stack</a>.</li>
<li><a href="https://github.com/sdiehl/protolude">Protolude</a></li>
<li><a href="http://haskellbook.com/">Haskell Programming from first principles</a>.</li>
</ol>

<hr />
<div id="comments">
  <div id="disqus_thread"></div>
  <script>
    var disqus_config = function () {
    this.page.url = "http://www.andrevdm.com/posts/2016-09-21-haskell-tfidf.html"; 
    this.page.identifier = "/posts/2016-09-21-haskell-tfidf.html"; 
    this.page.title = "Haskell text classification using Tf-Idf";
    };

    (function() { // DON'T EDIT BELOW THIS LINE
    var d = document, s = d.createElement('script');
    
    s.src = '//andrevdm.disqus.com/embed.js';
    
    s.setAttribute('data-timestamp', +new Date());
    (d.head || d.body).appendChild(s);
    })();
  </script>
  <noscript>Please enable JavaScript to view the <a href="https://disqus.com/?ref_noscript" rel="nofollow">comments powered by Disqus.</a></noscript>
</div>

<script id="dsq-count-scr" src="//andrevdm.disqus.com/count.js" async></script>

        </div>
        <div id="footer">
            Site proudly generated by
            <a href="http://jaspervdj.be/hakyll">Hakyll</a>
        </div>

        <script>
          (function(i,s,o,g,r,a,m){i['GoogleAnalyticsObject']=r;i[r]=i[r]||function(){
          (i[r].q=i[r].q||[]).push(arguments)},i[r].l=1*new Date();a=s.createElement(o),
          m=s.getElementsByTagName(o)[0];a.async=1;a.src=g;m.parentNode.insertBefore(a,m)
          })(window,document,'script','https://www.google-analytics.com/analytics.js','ga');
          
          ga('create', 'UA-78428674-1', 'auto');
          ga('send', 'pageview');
        </script>
    </body>
</html>
